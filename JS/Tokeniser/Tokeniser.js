const Tokeniser=(function(){return{settings:{operators:["<",">","=","+","-","*","/","?","!"],separators:[",",".",";",":"," ","\t","\n"],groupers:["(",")","[","]","{","}",'"',"'"],keepWhiteSpacesAsTokens:!1,trimTokens:!0},tokenType:function(t){return this.settings.operators.includes(t)?"operator":this.settings.separators.includes(t)?"separator":this.settings.groupers.includes(t)?"grouper":"other"},parseString:function(t){if("string"!=typeof t){if(null===t)return"null";t="object"==typeof t?JSON.stringify(t):t.toString()}let s=[],e="";for(let i=0;i<t.length;i++)this.tokenType(t[i])!==this.tokenType(e)||"separator"===this.tokenType(t[i])?(""!==e.trim()?s.push(this.settings.trimTokens?e.trim():e):this.settings.keepWhiteSpacesAsTokens&&s.push(e),e=t[i],"separator"===this.tokenType(e)&&(""!==e.trim()?s.push(this.settings.trimTokens?e.trim():e):this.settings.keepWhiteSpacesAsTokens&&s.push(e),e="")):e+=t[i];return""!==e.trim()?s.push(this.settings.trimTokens?e.trim():e):this.settings.keepWhiteSpacesAsTokens&&s.push(e),s}}})();console.log("Loaded Tokeniser.js by Matthew James");
